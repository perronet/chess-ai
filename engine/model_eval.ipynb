{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import setup\n",
    "import parse\n",
    "import utils\n",
    "import train\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load original dataset and plot score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(setup.DATASET_DIR+setup.DATASET_REGULAR, nrows=setup.N_ROWS*setup.DATASET_REGULAR_SIZE, dtype={\"Fen\": np.string_, \"Evaluation\": np.string_})\n",
    "df[\"Evaluation\"] = df[\"Evaluation\"].apply(lambda x: parse.stockfish_eval_to_int(x))\n",
    "df[\"Evaluation\"].plot.hist(bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random = pd.read_csv(setup.DATASET_DIR+setup.DATASET_RANDOM, nrows=setup.N_ROWS*setup.DATASET_RANDOM_SIZE, dtype={\"Fen\": np.string_, \"Evaluation\": np.string_})\n",
    "df_random[\"Evaluation\"] = df_random[\"Evaluation\"].apply(lambda x: parse.stockfish_eval_to_int(x))\n",
    "df_random[\"Evaluation\"].plot.hist(bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tactics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tactic = pd.read_csv(setup.DATASET_DIR+setup.DATASET_TACTIC, nrows=setup.N_ROWS*setup.DATASET_TACTIC_SIZE, dtype={\"Fen\": np.string_, \"Evaluation\": np.string_}, usecols=[0, 1])\n",
    "df_tactic[\"Evaluation\"] = df_tactic[\"Evaluation\"].apply(lambda x: parse.stockfish_eval_to_int(x))\n",
    "df_tactic[\"Evaluation\"].plot.hist(bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, df_random, df_tactic])[\"Evaluation\"].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, df_random, df_tactic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load vectorized dataset and plot normalized score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized = pd.read_csv(setup.DATASET_DIR+setup.DATASET_VECTORIZED)\n",
    "df_vectorized[\"label\"].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "assert df_vectorized[df_vectorized.isnull().values].empty\n",
    "# Check shape (+1 is for the label)\n",
    "assert df_vectorized.shape == (setup.N_ROWS_EFFECTIVE, setup.N_FEATURES + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, (history, train_error, cv_error) = train.create_model_and_train(df_vectorized)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate error and plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_learning_curve(history)\n",
    "y_cv = df_vectorized[\"label\"]\n",
    "print(f\"Training set error: {train_error:.2}\")\n",
    "print(f\"Cross-validation set error: {cv_error:.2}\")\n",
    "print(f\"Random classifier error: {((np.random.rand(len(y_cv)) - y_cv)**2).mean():.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup.SAVE_MODEL:\n",
    "    model.save(setup.MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup.K_FOLD:\n",
    "    features = [f\"f_{str(x)}\" for x in range(1, setup.N_FEATURES+1)]\n",
    "    k_fold = KFold(n_splits=setup.N_FOLDS)\n",
    "    train_error_all = []\n",
    "    cv_error_all = []\n",
    "    X = df_vectorized[features]\n",
    "    y = df_vectorized[\"label\"]\n",
    "\n",
    "    # TODO reset index first?\n",
    "    for i, (train, test) in enumerate(k_fold.split(X, y)):\n",
    "        model = create_model()\n",
    "        _, train_error, cv_error = train_evaluate_model(model, X.loc[train], y.loc[train], X.loc[test], y.loc[test])\n",
    "        train_error_all.append(train_error)\n",
    "        cv_error_all.append(cv_error)\n",
    "        print(f\"Model #{i+1} done! CV error: {cv_error:.2}\")\n",
    "        del model\n",
    "\n",
    "    print(f\"Training sets error:{train_error_all}\")\n",
    "    print(f\"Cross-validation sets sets errors:{cv_error_all}\")\n",
    "    print(f\"Training sets mean error: {np.mean(np.array(train_error_all)):.2}\")\n",
    "    print(f\"Cross-validation sets mean error: {np.mean(np.array(cv_error_all)):.2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
